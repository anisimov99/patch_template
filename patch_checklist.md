# Чеклист разработки патча

## Сбор требований и постановка задачи

### Создание целевых сущностей.

Запросить у аналитиков ЛМку. Выяснить:
1. Какие поля должны быть ключевыми? Есть ли в этих полях null на источнике? (такое бывает) Если есть, то какое дефолтное значение?
2. По каким полям следует делать партицирование? Обычно используется временнАя отчетная дата на источнике, значение которой для записей не обновляется/обновляется редко.
3. Как правильно маппить типы данных? Точно ли маппинг полей в ЛМке корректный? [Ссылка](https://docs.google.com/document/d/1Rg-wZCup3R7jOHMSE7WNUlD97-ULrnNCThRC2m8rgOc/edit) на док с маппингом основных типов из Postgres и MongoDB в Hive и Iceberg.
4. Нужно ли забирать с источника комментарии к полям и сущностям? Если да, то есть ли они в ЛМке?
5. Нужно ли создавать в целевой системе БД, или она считается уже созданной? (по умолчанию - нужно)
6. Какие у таблиц должны быть метаполя и как их правильно заполнять? Подробнее про это см. далее

### Создание загрузок

Описать тип загрузки в целевую систему. Выяснить тип загрузки - потоковая или пакетная.

Пакетная загрузка делается с помощью DAG'ов в Airflow, управляемых из УМа. DAG'и разрабатываются в соответствии с [шаблоном](https://confluence.moscow.alfaintra.net/pages/viewpage.action?pageId=1780104534) из документации ЕИСа.

Выяснить:
1. Какие из 6 тасок (типов загрузки) DAG'а следует реализовать?
2. В каком режиме будет работать DAG? Если по расписанию, то по какому?
3. Какие параметры следует вынести в УМ, а что оставить в самих тасках к ДАГу? Основная идея - параметризовать все с помощью УМа настолько, насколько это возможно.
4. Какие параметры из УМа следует передавать в таски? Какие это будут параметры - статические или динамические? Если параметр статический, то какое значение он хранит? Если параметр динамический, то какая функция УМа вычисляет его значение и какие аргументы эта функция получает на вход? Нужны ли переопределния статических параметров? 
5. Нужно ли реализовать логирование в УМ? Какие параметры следует логировать? Как это правильно сделать с т.з. внутренней организации УМа? Логирование в УМе работает только с регламентами, но не с атомарными потоками. Причем только с регламентами, поставленным на расписание. Поэтому если нужно логироваться, то в любом случае придется делать регламент в УМе и ставить его на расписание.
6. Какие метаполя следует добавить в целевые сущности для хранения информации, связанной с загрузкой данных? По умолчанию берем полный список из 12 метаполей из [стандарта](https://confluence.moscow.alfaintra.net/pages/viewpage.action?pageId=1757988205) архитектуры ЕИС. Чем заполнять эти поля при разных типах загрузки? Как эти поля будут обновляться с течением времени?

Потоковая загрузка: TBD.

## Разработка

Общие рекомендации:
1. Сразу именовать и раскладывать все по директориям в соответствии с [документацией](https://confluence.moscow.alfaintra.net/display/BDP/ICEBERG) ЕИСа. (!!!) Сэкономит много времени на этапе сдачи патча
2. В качестве референса следует использовать наш патч,  который одобрили и успешно выкатили на прод. Он лежит в ветке `CIDS-3` в рабочем [репозитории](https://git.moscow.alfaintra.net/projects/BI_CIDS/repos/cids/browse?at=refs%2Fheads%2FCIDS-3) на битбакете.

Общий пайплайн разработки:
Пишем ddl -> создаем нужные сущности в приемнике -> создаем даги и таски к ним -> загружаем их на сервер -> запускаем и убеждаемся, что данные льются

### Создание целевых сущностей

1. Где брать информацию? - При написании ddl сверяться с [документацией](https://confluence.moscow.alfaintra.net/display/BDP/ICEBERG). Там, в частности, описано:
* Как правильно называть сущности и БД для них
* Как правильно располагать сущности в бакете s3
* Какие у таблиц должны быть свойства `tblproperties`
* Как настроить в таблицах ключи и партицирование
2. Как должен выглядеть DDL для таблиц? - Последовательность команд: `DROP TABLE IF EXISTS <table_name>` -> `CREATE TABLE IF NOT EXISTS <table_name>` -> `ALTER TABLE <table_name> SET IDENTIFIER FIELDS <identifier_field_1>, <identifier_field_2>;` -> `ALTER TABLE <table_name> WRITE DISTRIBUTED BY PARTITION LOCALLY ORDERED BY <partition_field_1> ASC NULLS LAST, <partition_field_2> ASC NULLS LAST;`
3. Как должен выглядеть DDL для БД? - `DROP DATABASE IF EXISTS <db_name>` -> `CREATE DATABASE IF NOT EXISTS <db_name>`
4. Какие у таблицы должны быть свойства? - Полный сбор статистик (`write.metadata.metrics.column.<column_name> = 'full'`) следует указывать для всех ключевых атрибутов и атрибутов, по которым выполняется партицирование таблицы. Другие свойства можно указывать без изменений:
```
'write.parquet.compression-codec' = 'zstd',
'write.parquet.compression-level' = '3',
'history.expire.max-snapshot-age-ms' = '86400000'
'format' = 'iceberg/parquet',
'format-version' = '2',
'write.delete.mode' = 'merge-on-read',
'write.merge.mode' = 'merge-on-read',
'write.update.mode' = 'merge-on-read',
'write.distribution-mode' = 'hash',
'write.metadata.delete-after-commit.enabled' = 'true',
'write.metadata.previous-versions-max' = '100',
```

### Создание DAG'ов загрузки

При разработке следует опираться на имеющийся [шаблон](https://confluence.moscow.alfaintra.net/pages/viewpage.action?pageId=1780104534) DAG

За примерами см. [референс](https://git.moscow.alfaintra.net/projects/BI_CIDS/repos/cids/browse?at=refs%2Fheads%2FCIDS-3)

Куда смотреть, если есть ошибки с DAG'ами? - первое - логи Airflow. Если ошибка вида `Cannot execute: spark-submit ...`, то это значит, что airflow не удалось корректно развернуть спарк-приложение в кубере, либо приложение развернулось и упало с ошибкой. Нужно идти дальше и смотреть логи кубера (если, конечно, у тебя есть к ним доступ ...)

Данный шаблон требует следующих доработок:
1. Поменять все комменты на английский, иначе будут потом проблемы с кодировками при сборке патча (см. выше)
2. Выкинуть из шаблона функции `join_path_to_config()`, `generate_params_from_yaml()`, `calculate_required_resources()` и все места, где происходит обращение к ним. Они были нужны на том этапе разработки, когда у нас не было интеграции с УМом, и мы были вынуждены использовать `.yaml`-конфиг для параметризации работы DAG'ов. Сейчас это не актуально
3. Добавить в таску ветвления `task_branch` считывание параметра ветвления `$$P_BRANCH_PARAM` из УМа
4. Реализовать таску `log_paramprevvalue` с помощью `SparkSubmitOperator`, передать туда нужные параметры из УМа
5. Поменять jinja-параметр `{{ spark_conn_id }}` на коннетор до среды, в которой будет разворачиваться спарк-приложение. В нашем случае это был коннектор до кубера `spark_k8s`
6. Во всех тасках заменить считывание из `xcom` на считывание из УМа. `xcom` был нужен, когда у нас использовался `.yaml`-конфиг, сейчас это не актуально
7. Поменять jinja-параметр `{{ conn_id }}` на коннектор до источника данных. Коннектор настраивается в веб-интерфейсе Airflow, на верхней панели управления вкладка `Admin` -> `Connections`
8. Для режимов загрузки, которые не планируется реализовывать, таски следует изменить со `SparkSubmitOperator` на `EmptyOperator`

### Создание скриптов для DAG'ов загрузки

Общие правила:
1. Везде в настройках спарк-сессии проставлять московский часовой пояс
2. Учесть, что параметры из УМа в скрипты передаются в виде строк, независимо от фактического типа данных, который они содержат по смыслу -> некоторые из полей надо явно кастить в нужный тип. Например, `$$P_DMSJOB` кастится в `int`, `$$P_LAST_AS_OF_DAY` - в `timestamp` через `to_timestamp` внутри запроса, и т.д.
3. В настройках сессии следует указывать количество ресрсов для спарк-сессии. Мы явно проставили количество памяти на один экзекьютор `spark.executor.memory=5G` для таско загрузки данных. При попытке добавить возможности динамического выделения памяти `spark.dynamicAllocation.enable=true` DAG падал, ввиду отсутствие доступа к логам среды запуска нам так и не удалось утсановить причину ошибки

Скрипт для полной перезагрузки таблицы `load_init_full`
1. Имена полей следует считывать с целевой таблицы через `spark.sql('select * from <table_name>').schema.fieldNames()`, а не писать явно длинной строкой в скрипте
2. Ключевые поля, в которых есть `null`'ы, заполняются значениями по умолчанию
3. Перед загрузкой данных в целевой таблице делается `TRUNCATE`, чтобы полностью очистить и залить данные по новой
4. Для записи данных в целевую таблицу следует использовать метод `DataFrame.writeTo(<table_name>).overwritePartitions()`. Он умеет автоматически мэтчить поля по именам и кастить их в нужный тип
5. Чем заполнять метаполя при вставке новой строки? - см. референс.

Скрипт для загрузки дельты изменений `load_reg_key_merge`
1. См. замечания 1, 2, 4 и 5 для `load_init_full`
2. Какие поля обновлять при обновлении строки? Чем их заполнять? - см. референс.

Скрипт для логирования `LAST_AS_OF_DAY`
1. Забирать максимальное значение по полю `src_modified_stamp`, записывать в таблицу УМа `log_paramprevvalue`, имя параметра - `$$P_LAST_AS_OF_DAY`

### Интеграция DAG'ов загрузки с УМом

1. Все вставки в таблицы метаданных выполняются с помощью API `UTL_MD_UPSERT`, **никаких ручных вставок**. Справка по API есть в [документации](https://confluence.moscow.alfaintra.net/pages/viewpage.action?pageId=441522681) УМа.
2. Для корретного логирования и считывания залогированных параметров из УМа **требуется**, чтобы атомарный поток был включен в регламент, а этот регламент был поставлен на расписание. Иначе логаться в УМ не получится. Если на текущем этапе разработки расписание фактически не требуется, но при этом хочется протестировать возможность логирования, то можно поставить регламент на виртуальное (т.е. "пустое") расписание - оно позволит корректно логироваться, но при этом фактически никак не будет влиять на поведение регламента. Код для создания такого виртуального расписания:
```PLSQL
v_res := utl_md_upsert.upsert_sch(
p_sch_name => 'EMPTY_SCHEDULE',
p_run_mode => 'N/A',
p_querry => '',
p_description => 'Пустое расписание',
p_patch_code => 'PATCH_CODE'
);
```
3. После постановки регламента на уже реальное расписание с ежедневным запуском (т.е. расписание типа `DAILY`) требуется провести дополнительные манипуляции с таблицами логирования. А именно:
    1. Вставить в `log_loading` запись, что регламент отработал за предыдущий опер. день: `insert into log_loading VALUES (seq_loading.nextval, <reg_name>, sysdate, sysdate, 'SUCCEEDED', TRUNC(SYSDATE)-1 );`
    2. Вставить в  `log_as_of_day` запись для нового ежедневного регламента: `insert into log_as_of_day values (trunc(sysdate), sysdate, 'WF_CONTROL', 'WF_REG_DWH4DM_REGULAR_KPI');`
    Подробнее про это мо

Куда смотреть, если есть ошибки с УМом? - смотри таблицы логирования:
* `log_loading` - логирование регламентов, статус регламента
* `log_job` - логи атомарных потоков, в т.ч. запускаемых в рамках регламента
* `log_lauchrequest` - лог заявок на запуск атомарных потоков в рамках регламента. "Ушла ли заявка на запуск?"
* `log_as_of_day` - логирование опердня регламента

Инструкция:
1. Создать атомарный поток с помощью `UTL_MD_UPSERT.UPSERT_WF`. Происходит upsert записи в таблицу `md_workflows`
2. Создать регламент с помощью `UTL_MD_UPSERT.UPSERT_REG`. Происходит upsert записи в таблицу `md_regs`
3. Включить атомарный поток в регламент с помощью `UTL_MD_UPSERT.UPSERT_WF2REG`. Происходит upsert записи в таблицу `md_workflow2reg` (связь многие-ко-многим)
4. Связать атомарный поток с обновляемой сущностью с помощью `UTL_MD_UPSERT.UPSERT_WF2REG`. Происходит upsert записи в таблицу `md_workflow2table`
5. Добавить значения статических параметров для запусков регламента с помощью `UTL_MD_UPSERT.UPSERT_STATPARAM`. Происходит upsert записи в таблицу `md_ipcobjparams`, которая хранит связь регламента со значением параметра, передаваемом ему при запуске. Если какой-то параметр добавляется в УМ впервые, то его сначала необходимо добавить в таблицу `UTL_MD_UPSERT.UPSERT_PARAMETERS`, чтобы он появился в `md_parameters`. И уже после этого мы можем добавить в УМ значение этого параметра, связанное с запуском нашего регламента
6. Добавить функции для вычисления значений динамических параметров при запуске регламента с помощью `UTL_MD_UPSERT.UPSERT_DYNAMPARAM`. Происходит upsert записи в таблицу `md_ipcobjparams`.
7. Если какой-то статический параметр нуждается в переопределении, то это также следует добавить. Для этого нужно очистить стек переопределений этого параметра с помощью `UTL_MD_UPSERT.DELETE_USRPARAM`. При этом происходит удаление всех нереализованных (т.е. имеющих `job_id=null`) переопределений данного параметра из таблицы `usr_ipcobjparamoverride`. После этого следует добавить требуемое переопределение с помощью `UTL_MD_UPSERT.INSERT_USRPARAM`. При этом происходит вставка новой записи в  `usr_ipcobjparamoverride`. Очищаем стек переопределений и кладем на его вершину новое значение.
8. Создать расписание для регламента с помощью `UTL_MD_UPSERT.UPSERT_SCH`. Происходит upsert записи в таблицу `md_schedule`
9. Связать ранее созданный регламент с этим расписанием с помощью `UTL_MD_UPSERT.UPSERT_REG`, указав имя нужного регламента и нужное расписание. По поводу нюансов, связанных с расписаниями, см. выше.

### Создание DAG'ов обслуживания

TBD

### Создание скриптов для DAG'ов обслуживания

TBD

## Сборка патча

Инструкция по размещению файлов в репозитории приведена в [документации](https://confluence.moscow.alfaintra.net/pages/viewpage.action?pageId=967671696)

Общие замечания:
1. Платформа для сборки патча не умеет работать с кодировками UTF. Это незаметно до тех пор, пока у тебя исходники не содержат не-ASCII символов. В противном же случае, - например, если у тебя в файлах есть комментарии к атрибутам или к коду на русском языке, - при работе с этими файлами следует всегда (!) явно (!) переключать в редакторе кода кодировку с UTF-8 на Windows-1251. Иначе можно легко по невнимательности сохранить файл в неправильной кодировке и испортить его, придется откатываться до последнего коммита в гите и начинать всю работу заново. **Внимательнее с кодировками!**

### DDL-скрипты для целевых сущностей и БД

Имя ddl для таблицы: `<source_system>__<database_name>__<schema_name>__<table_name>.sql`
Здесь:
* `<source_system>` - наименование системы-источника
* `<database_name>` - имя БД в источнике
* `<schema_name>` - имя схемы в БД на источнике
* `<table_name>` - имя таблицы в БД на источнике
Пример: пусть у нас есть система-источник `bix`, которая хранит в БД `bixdb` схему `public`, в которой лежит таблица `claimitems`. Тогда скрипт будет называться `bix__bixdb__public__claimitems.sql`.
Путь до ddl для таблиц: `cids\DB\Spark\CIDS\ICEBERG\table\<table_ddl_name>.sql`.

Имя ddl для БД: `<source_system>__<database_name>.sql`
Путь до ddl для БД: `cids\DB\Spark\CIDS\ICEBERG\tablespace\<db_ddl_name>.sql`. Используется папка tablespace, т.к. папка database пока не поддерживается девопс-конвеером и не проходит nft-тесты.
Для нашего примера DDL-скрипт для БД будет называться `bix__bixdb.sql`

### DAG'и загрузки и скрипты к ним

См. [референс](https://git.moscow.alfaintra.net/projects/BI_CIDS/repos/cids/browse?at=refs%2Fheads%2FCIDS-3) и [документацию](https://confluence.moscow.alfaintra.net/display/BDP/Airflow).

### DAG'и обслуживания и скрипты к ним

См. [референс](https://git.moscow.alfaintra.net/projects/BI_CIDS/repos/cids/browse?at=refs%2Fheads%2FCIDS-3) и [документацию](https://confluence.moscow.alfaintra.net/display/BDP/Airflow).

### DML-скрипты для УМа

См. [референс](https://git.moscow.alfaintra.net/projects/BI_CIDS/repos/cids/browse?at=refs%2Fheads%2FCIDS-3)

## Дальнейшие пожелания по разработке, техдолг

1. Перенести в УМ вообще все, что сейчас статично задается в DAG'ах или скриптах к ним. А именно:
* SQL-запросы к источнику
* Коннекторы подключения к источнику
* Ресурсы спарк-сессии для таски
* Возможно, что-то ещё... 
2. Разобраться с выделением ресурсов для спарк-сессии - почему падает спарк-приложение? Нужны логи кубера
3. Интегрировать DAG'и обслуживания с УМом, добавить их в регламент, поставить на расписание
